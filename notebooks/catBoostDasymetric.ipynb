{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0622cf",
   "metadata": {},
   "source": [
    "# CatBoost Dasymetric Poverty Mapping Notebook\n",
    "\n",
    "## Checklist\n",
    "- Load and validate input feature and target datasets\n",
    "- Prepare training matrix (fractional assignment already baked into engineered dataset)\n",
    "- Train CatBoost with cross-validation and capture metrics\n",
    "- Generate predictions and evaluation plots\n",
    "- Save all tabular outputs (CSV) and visualizations (PNG)\n",
    "- Copy Random Forest outputs and create comparison manifest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d2e17-65cc-4176-a845-5a4b8c9e24bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc041969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CATBOOST DASYMETRIC POVERTY MAPPING ===\n",
      "\n",
      "Checking for engineered dataset:\n",
      "  ..\\assets\\grid_with_comprehensive_data.csv: ✓ Found\n",
      "  ..\\assets\\grid_features_engineered.csv: ✓ Found\n",
      "  ..\\assets\\grid_features_spatial_imputed.csv: ✓ Found\n",
      "\n",
      "✓ Using dataset: ..\\assets\\grid_with_comprehensive_data.csv\n",
      "✓ Loaded 1724 rows and 73 columns\n",
      "✓ Target column: poverty_rate\n",
      "✓ Training samples (with poverty data): 1724\n",
      "✓ Feature columns: 67\n",
      "⚠ Filling 80 missing values with column means\n",
      "✓ Categorical features detected: 3\n",
      "\n",
      "Dataset ready for training:\n",
      "  Features shape: (1724, 67)\n",
      "  Target shape: (1724,)\n",
      "  Target range: [0.190, 0.798]\n",
      "  Target mean: 0.498\n",
      "\n",
      "=== CROSS-VALIDATION (5-FOLD) ===\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 128\u001b[39m\n\u001b[32m    126\u001b[39m r2 = r2_score(y_test, preds)\n\u001b[32m    127\u001b[39m mae = mean_absolute_error(y_test, preds)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m rmse = \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m cv_rows.append({\u001b[33m'\u001b[39m\u001b[33mfold\u001b[39m\u001b[33m'\u001b[39m: fold_num, \u001b[33m'\u001b[39m\u001b[33mr2\u001b[39m\u001b[33m'\u001b[39m: r2, \u001b[33m'\u001b[39m\u001b[33mmae\u001b[39m\u001b[33m'\u001b[39m: mae, \u001b[33m'\u001b[39m\u001b[33mrmse\u001b[39m\u001b[33m'\u001b[39m: rmse})\n\u001b[32m    131\u001b[39m feature_importance_accum += model.get_feature_importance(train_pool)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\povertymapping\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:196\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m params = \u001b[43mfunc_sig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m params.apply_defaults()\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\povertymapping\\Lib\\inspect.py:3195\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3191\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3192\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3193\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3194\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\povertymapping\\Lib\\inspect.py:3184\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3182\u001b[39m         arguments[kwargs_param.name] = kwargs\n\u001b[32m   3183\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3185\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   3186\u001b[39m                 arg=\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[32m   3188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[31mTypeError\u001b[39m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Directories - relative to notebook location\n",
    "OUTPUT_ROOT = Path('../output/catBoost')\n",
    "DATA_OUT = OUTPUT_ROOT / 'data'\n",
    "VIS_OUT = OUTPUT_ROOT / 'visualizations'\n",
    "RF_OUT = OUTPUT_ROOT / 'randomForest_outputs'\n",
    "for d in [DATA_OUT, VIS_OUT, RF_OUT]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Helper: fail fast with clear message\n",
    "def abort(msg: str):\n",
    "    print(f\"ERROR: {msg}\")\n",
    "    raise SystemExit(1)\n",
    "\n",
    "print(\"=== CATBOOST DASYMETRIC POVERTY MAPPING ===\\n\")\n",
    "\n",
    "# Locate engineered dataset - PRIORITIZE spatially-imputed for fair comparison\n",
    "ENGINEERED_PATHS = [\n",
    "    Path('../assets/grid_features_spatial_imputed.csv'),  # FIRST: Same as RandomForest\n",
    "    Path('../assets/grid_with_comprehensive_data.csv'),\n",
    "    Path('../assets/grid_features_engineered.csv'),\n",
    "]\n",
    "\n",
    "print(\"Checking for engineered dataset:\")\n",
    "engineered_file = None\n",
    "for p in ENGINEERED_PATHS:\n",
    "    exists = p.exists()\n",
    "    print(f\"  {p}: {'✓ Found' if exists else '✗ Not found'}\")\n",
    "    if exists and engineered_file is None:\n",
    "        engineered_file = p\n",
    "\n",
    "if engineered_file is None:\n",
    "    abort('No engineered dataset found. Please run the data preparation notebooks first.')\n",
    "\n",
    "print(f\"\\n✓ Using dataset: {engineered_file}\")\n",
    "if 'spatial_imputed' in str(engineered_file):\n",
    "    print(\"  ✅ Using same spatially-imputed data as RandomForest for fair comparison\")\n",
    "\n",
    "# Load dataset\n",
    "try:\n",
    "    df = pd.read_csv(engineered_file)\n",
    "    print(f\"✓ Loaded {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "except Exception as e:\n",
    "    abort(f'Failed to read dataset: {e}')\n",
    "\n",
    "# Check for poverty_rate column (same as RandomForest)\n",
    "if 'poverty_rate' not in df.columns:\n",
    "    abort(f\"Dataset missing 'poverty_rate' column. Available columns: {list(df.columns)}\")\n",
    "\n",
    "TARGET = 'poverty_rate'\n",
    "print(f\"✓ Target column: {TARGET}\")\n",
    "\n",
    "# Filter to rows with poverty data (training set)\n",
    "df_train = df[df[TARGET].notna()].copy()\n",
    "print(f\"✓ Training samples (with poverty data): {len(df_train)}\")\n",
    "\n",
    "if len(df_train) == 0:\n",
    "    abort(\"No training samples found (all poverty_rate values are null)\")\n",
    "\n",
    "# Prepare features - exclude non-feature columns (same as RandomForest)\n",
    "EXCLUDE_COLS = [\n",
    "    TARGET, 'grid_id', '.geo', 'system:index', 'x_idx', 'y_idx', \n",
    "    'geometry', 'barangay_name', 'lon', 'lat', 'centroid', 'cluster'\n",
    "]\n",
    "feature_cols = [c for c in df_train.columns if c not in EXCLUDE_COLS]\n",
    "print(f\"✓ Feature columns: {len(feature_cols)}\")\n",
    "\n",
    "X = df_train[feature_cols].copy()\n",
    "y = df_train[TARGET].copy()\n",
    "\n",
    "# Handle missing values (mean imputation for consistency)\n",
    "missing_before = X.isnull().sum().sum()\n",
    "if missing_before > 0:\n",
    "    print(f\"⚠ Filling {missing_before} missing values with column means\")\n",
    "    X = X.apply(lambda s: s.fillna(s.mean()) if s.dtype in ['float64', 'int64'] else s)\n",
    "else:\n",
    "    print(f\"✓ No missing values - spatial imputation already applied\")\n",
    "\n",
    "# Identify categorical features\n",
    "cat_features = []\n",
    "for i, col in enumerate(feature_cols):\n",
    "    if X[col].dtype == 'object' or (X[col].dtype in ['int64', 'float64'] and X[col].nunique() < 10):\n",
    "        cat_features.append(i)\n",
    "\n",
    "print(f\"✓ Categorical features detected: {len(cat_features)}\")\n",
    "print(f\"\\nDataset ready for training:\")\n",
    "print(f\"  Features shape: {X.shape}\")\n",
    "print(f\"  Target shape: {y.shape}\")\n",
    "print(f\"  Target range: [{y.min():.3f}, {y.max():.3f}]\")\n",
    "print(f\"  Target mean: {y.mean():.3f}\")\n",
    "\n",
    "# Cross-validation\n",
    "print(f\"\\n=== CROSS-VALIDATION (5-FOLD) ===\")\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_rows = []\n",
    "fold_num = 1\n",
    "feature_importance_accum = np.zeros(len(feature_cols))\n",
    "\n",
    "for train_idx, test_idx in kfold.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "    test_pool = Pool(X_test, y_test, cat_features=cat_features)\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=500,\n",
    "        depth=8,\n",
    "        learning_rate=0.05,\n",
    "        loss_function='RMSE',\n",
    "        eval_metric='RMSE',\n",
    "        verbose=False,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(train_pool, eval_set=test_pool)\n",
    "\n",
    "    preds = model.predict(test_pool)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "    cv_rows.append({'fold': fold_num, 'r2': r2, 'mae': mae, 'rmse': rmse})\n",
    "    feature_importance_accum += model.get_feature_importance(train_pool)\n",
    "    print(f\"Fold {fold_num}: R²={r2:.4f}, MAE={mae:.4f}, RMSE={rmse:.4f}\")\n",
    "    fold_num += 1\n",
    "\n",
    "cv_df = pd.DataFrame(cv_rows)\n",
    "cv_summary = cv_df[['r2', 'mae', 'rmse']].mean()\n",
    "print(f\"\\nCV Summary:\")\n",
    "print(f\"  Mean R²: {cv_summary['r2']:.4f}\")\n",
    "print(f\"  Mean MAE: {cv_summary['mae']:.4f}\")\n",
    "print(f\"  Mean RMSE: {cv_summary['rmse']:.4f}\")\n",
    "\n",
    "cv_df.to_csv(DATA_OUT / 'catboost_cv_metrics.csv', index=False)\n",
    "print(f\"✓ Saved CV metrics to {DATA_OUT / 'catboost_cv_metrics.csv'}\")\n",
    "\n",
    "# Train final model on full training set\n",
    "print(f\"\\n=== TRAINING FINAL MODEL ===\")\n",
    "full_pool = Pool(X, y, cat_features=cat_features)\n",
    "final_model = CatBoostRegressor(\n",
    "    iterations=800,\n",
    "    depth=8,\n",
    "    learning_rate=0.03,\n",
    "    loss_function='RMSE',\n",
    "    eval_metric='RMSE',\n",
    "    verbose=False,\n",
    "    random_state=42\n",
    ")\n",
    "final_model.fit(full_pool)\n",
    "print(\"✓ Final model trained\")\n",
    "\n",
    "# Feature importance\n",
    "avg_importance = feature_importance_accum / kfold.get_n_splits()\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'cv_importance': avg_importance,\n",
    "    'full_importance': final_model.get_feature_importance(full_pool)\n",
    "})\n",
    "importance_df = importance_df.sort_values('full_importance', ascending=False)\n",
    "importance_df.to_csv(DATA_OUT / 'catboost_feature_importance.csv', index=False)\n",
    "print(f\"✓ Saved feature importance to {DATA_OUT / 'catboost_feature_importance.csv'}\")\n",
    "\n",
    "print(f\"\\nTop 10 most important features:\")\n",
    "for idx, row in importance_df.head(10).iterrows():\n",
    "    print(f\"  {row['feature']}: {row['full_importance']:.1f}\")\n",
    "\n",
    "# Predictions on training set (in-sample)\n",
    "full_preds = final_model.predict(full_pool)\n",
    "pred_df = pd.DataFrame({\n",
    "    'grid_id': df_train['grid_id'] if 'grid_id' in df_train.columns else range(len(y)),\n",
    "    'actual': y,\n",
    "    'predicted': full_preds,\n",
    "    'residual': y - full_preds\n",
    "})\n",
    "pred_df.to_csv(DATA_OUT / 'catboost_predictions.csv', index=False)\n",
    "print(f\"✓ Saved predictions to {DATA_OUT / 'catboost_predictions.csv'}\")\n",
    "\n",
    "# Predict on full dataset (including cells without poverty data)\n",
    "print(f\"\\n=== PREDICTING ON FULL GRID ===\")\n",
    "X_full = df[feature_cols].copy()\n",
    "X_full = X_full.apply(lambda s: s.fillna(s.mean()) if s.dtype in ['float64', 'int64'] else s)\n",
    "full_grid_preds = final_model.predict(Pool(X_full, cat_features=cat_features))\n",
    "\n",
    "full_pred_df = pd.DataFrame({\n",
    "    'grid_id': df['grid_id'] if 'grid_id' in df.columns else range(len(df)),\n",
    "    'poverty_rate_predicted': full_grid_preds\n",
    "})\n",
    "if TARGET in df.columns:\n",
    "    full_pred_df['poverty_rate_actual'] = df[TARGET]\n",
    "\n",
    "full_pred_df.to_csv(DATA_OUT / 'catboost_full_grid_predictions.csv', index=False)\n",
    "print(f\"✓ Predicted poverty for {len(df)} grid cells\")\n",
    "print(f\"✓ Saved to {DATA_OUT / 'catboost_full_grid_predictions.csv'}\")\n",
    "\n",
    "# Visualizations\n",
    "print(f\"\\n=== GENERATING VISUALIZATIONS ===\")\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# 1. Feature importance plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "imp_top = importance_df.head(20)\n",
    "plt.barh(range(len(imp_top)), imp_top['full_importance'], color='steelblue')\n",
    "plt.yticks(range(len(imp_top)), imp_top['feature'])\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('CatBoost Feature Importance (Top 20)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(VIS_OUT / 'catboost_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"✓ Saved {VIS_OUT / 'catboost_feature_importance.png'}\")\n",
    "\n",
    "# 2. Predicted vs Actual\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(pred_df['actual'], pred_df['predicted'], alpha=0.6, s=20)\n",
    "plt.xlabel('Actual Poverty Rate')\n",
    "plt.ylabel('Predicted Poverty Rate')\n",
    "plt.title(f'CatBoost: Predicted vs Actual\\n(R² = {r2_score(pred_df[\"actual\"], pred_df[\"predicted\"]):.3f})')\n",
    "lims = [0, max(pred_df['actual'].max(), pred_df['predicted'].max())]\n",
    "plt.plot(lims, lims, 'r--', alpha=0.7, linewidth=2)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(VIS_OUT / 'catboost_pred_vs_actual.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"✓ Saved {VIS_OUT / 'catboost_pred_vs_actual.png'}\")\n",
    "\n",
    "# 3. Residual distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(pred_df['residual'], bins=40, kde=True, color='purple')\n",
    "plt.axvline(0, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "plt.xlabel('Residual (Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('CatBoost Residual Distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig(VIS_OUT / 'catboost_residuals.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"✓ Saved {VIS_OUT / 'catboost_residuals.png'}\")\n",
    "\n",
    "# 4. CV metrics plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_pos = np.arange(len(cv_df))\n",
    "width = 0.25\n",
    "\n",
    "plt.bar(x_pos - width, cv_df['r2'], width, label='R²', alpha=0.8)\n",
    "plt.bar(x_pos, cv_df['mae'], width, label='MAE', alpha=0.8)\n",
    "plt.bar(x_pos + width, cv_df['rmse'], width, label='RMSE', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('CatBoost Cross-Validation Metrics by Fold')\n",
    "plt.xticks(x_pos, [f'Fold {i+1}' for i in range(len(cv_df))])\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(VIS_OUT / 'catboost_cv_metrics.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"✓ Saved {VIS_OUT / 'catboost_cv_metrics.png'}\")\n",
    "\n",
    "# Copy Random Forest outputs for comparison\n",
    "print(f\"\\n=== COPYING RANDOM FOREST OUTPUTS ===\")\n",
    "import shutil\n",
    "\n",
    "rf_copied = []\n",
    "\n",
    "# Look for RandomForest output directories\n",
    "rf_search_dirs = [\n",
    "    Path('../output/randomForest'),\n",
    "    Path('../output/rf'),\n",
    "    Path('../output/random_forest'),\n",
    "]\n",
    "\n",
    "for rf_dir in rf_search_dirs:\n",
    "    if rf_dir.exists():\n",
    "        print(f\"Found RF output directory: {rf_dir}\")\n",
    "        for item in rf_dir.rglob('*'):\n",
    "            if item.is_file():\n",
    "                rel_path = item.relative_to(rf_dir)\n",
    "                dest = RF_OUT / rel_path\n",
    "                dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "                try:\n",
    "                    shutil.copy2(item, dest)\n",
    "                    rf_copied.append(str(rel_path))\n",
    "                except Exception as e:\n",
    "                    print(f\"  ⚠ Failed to copy {item}: {e}\")\n",
    "        break\n",
    "\n",
    "# Create manifest\n",
    "manifest_path = RF_OUT / 'randomForest_output_list.md'\n",
    "with open(manifest_path, 'w', encoding='utf-8') as f:\n",
    "    f.write('# Random Forest Output Files (for Comparison)\\n\\n')\n",
    "    f.write(f'Copied from RandomForest model outputs for side-by-side comparison.\\n\\n')\n",
    "    if rf_copied:\n",
    "        f.write(f'## Files Copied ({len(rf_copied)})\\n\\n')\n",
    "        for fp in sorted(rf_copied):\n",
    "            f.write(f'- `{fp}`\\n')\n",
    "    else:\n",
    "        f.write('⚠ No Random Forest outputs found to copy.\\n')\n",
    "        f.write('\\nSearched in:\\n')\n",
    "        for d in rf_search_dirs:\n",
    "            f.write(f'- {d}\\n')\n",
    "\n",
    "print(f\"✓ Saved manifest to {manifest_path}\")\n",
    "if rf_copied:\n",
    "    print(f\"✓ Copied {len(rf_copied)} RF output files\")\n",
    "else:\n",
    "    print(f\"⚠ No RF outputs found (run RandomForest notebook first)\")\n",
    "\n",
    "# Save run metadata\n",
    "run_meta = {\n",
    "    'dataset': str(engineered_file),\n",
    "    'target': TARGET,\n",
    "    'n_samples': len(df_train),\n",
    "    'n_features': len(feature_cols),\n",
    "    'n_categorical': len(cat_features),\n",
    "    'cv_r2_mean': cv_summary['r2'],\n",
    "    'cv_mae_mean': cv_summary['mae'],\n",
    "    'cv_rmse_mean': cv_summary['rmse'],\n",
    "}\n",
    "pd.DataFrame([run_meta]).to_csv(DATA_OUT / 'catboost_run_metadata.csv', index=False)\n",
    "print(f\"✓ Saved run metadata to {DATA_OUT / 'catboost_run_metadata.csv'}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"✓ CATBOOST WORKFLOW COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nOutputs saved to:\")\n",
    "print(f\"  Data: {DATA_OUT}\")\n",
    "print(f\"  Visualizations: {VIS_OUT}\")\n",
    "print(f\"  RF Comparison: {RF_OUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2851c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MAPPING OUTPUTS ===\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CREATING CATBOOST POVERTY MAPS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare data - load grid with geometry\n",
    "grid_file = engineered_file.with_suffix('.geojson')\n",
    "if not grid_file.exists():\n",
    "    # Try alternative paths\n",
    "    alt_paths = [\n",
    "        Path('../assets/grid_with_comprehensive_data.geojson'),\n",
    "        Path('../assets/grid_cells.geojson'),\n",
    "        Path('../assets/grid_with_poverty_predictions.geojson'),\n",
    "    ]\n",
    "    for p in alt_paths:\n",
    "        if p.exists():\n",
    "            grid_file = p\n",
    "            break\n",
    "\n",
    "if not grid_file.exists():\n",
    "    print(f\"⚠ Grid GeoJSON file not found. Cannot create maps.\")\n",
    "    print(f\"  Searched: {grid_file} and alternatives\")\n",
    "    print(f\"  Predictions saved to CSV: {DATA_OUT / 'catboost_full_grid_predictions.csv'}\")\n",
    "else:\n",
    "    import geopandas as gpd\n",
    "    \n",
    "    print(f\"Loading grid geometry from {grid_file}\")\n",
    "    grid_gdf = gpd.read_file(grid_file)\n",
    "    \n",
    "    # Merge with predictions\n",
    "    if 'grid_id' in full_pred_df.columns and 'grid_id' in grid_gdf.columns:\n",
    "        grid_gdf = grid_gdf.merge(full_pred_df[['grid_id', 'poverty_rate_predicted']], \n",
    "                                 on='grid_id', how='left')\n",
    "    else:\n",
    "        # If no grid_id, assume same order\n",
    "        grid_gdf['poverty_rate_predicted'] = full_pred_df['poverty_rate_predicted'].values\n",
    "    \n",
    "    # Create figure with multiple maps\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    \n",
    "    # ============================================================================\n",
    "    # MAP 1: Predicted Poverty Rate (Grid Level)\n",
    "    # ============================================================================\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    grid_gdf.plot(column='poverty_rate_predicted', \n",
    "                 ax=ax1, \n",
    "                 cmap='RdYlGn_r', \n",
    "                 legend=True,\n",
    "                 vmin=0, vmax=1,\n",
    "                 edgecolor='gray',\n",
    "                 linewidth=0.1,\n",
    "                 legend_kwds={'label': 'Predicted Poverty Rate', 'shrink': 0.8})\n",
    "    \n",
    "    ax1.set_title('CatBoost Predicted Poverty Rate\\n(Grid Level - 1km²)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Longitude')\n",
    "    ax1.set_ylabel('Latitude')\n",
    "    ax1.grid(True, alpha=0.2)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # MAP 2: Actual vs Predicted (Training cells only)\n",
    "    # ============================================================================\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    if 'poverty_rate' in grid_gdf.columns:\n",
    "        # Show only cells with actual data\n",
    "        training_cells = grid_gdf[grid_gdf['poverty_rate'].notna()].copy()\n",
    "        training_cells['error'] = abs(training_cells['poverty_rate'] - \n",
    "                                     training_cells['poverty_rate_predicted'])\n",
    "        \n",
    "        training_cells.plot(column='error', \n",
    "                          ax=ax2, \n",
    "                          cmap='Reds', \n",
    "                          legend=True,\n",
    "                          vmin=0, vmax=0.3,\n",
    "                          edgecolor='gray',\n",
    "                          linewidth=0.1,\n",
    "                          legend_kwds={'label': 'Absolute Error', 'shrink': 0.8})\n",
    "        \n",
    "        mean_error = training_cells['error'].mean()\n",
    "        ax2.set_title(f'Prediction Error (Absolute)\\nMean Error: {mean_error:.4f}', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'No actual data available\\nfor error mapping', \n",
    "                ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "        ax2.set_title('Prediction Error (Absolute)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax2.set_xlabel('Longitude')\n",
    "    ax2.set_ylabel('Latitude')\n",
    "    ax2.grid(True, alpha=0.2)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # MAP 3: High Poverty Areas (Classification)\n",
    "    # ============================================================================\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    # Classify cells\n",
    "    grid_gdf['poverty_class'] = pd.cut(grid_gdf['poverty_rate_predicted'], \n",
    "                                       bins=[0, 0.3, 0.5, 0.7, 1.0],\n",
    "                                       labels=['Low (<30%)', 'Medium (30-50%)', \n",
    "                                              'High (50-70%)', 'Very High (>70%)'])\n",
    "    \n",
    "    # Color map\n",
    "    class_colors = {'Low (<30%)': 'green', \n",
    "                   'Medium (30-50%)': 'yellow', \n",
    "                   'High (50-70%)': 'orange', \n",
    "                   'Very High (>70%)': 'red'}\n",
    "    \n",
    "    for class_name, color in class_colors.items():\n",
    "        subset = grid_gdf[grid_gdf['poverty_class'] == class_name]\n",
    "        if len(subset) > 0:\n",
    "            subset.plot(ax=ax3, color=color, edgecolor='gray', linewidth=0.1, alpha=0.7)\n",
    "    \n",
    "    # Create legend\n",
    "    legend_elements = [Patch(facecolor=color, label=label) \n",
    "                      for label, color in class_colors.items()]\n",
    "    ax3.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
    "    \n",
    "    ax3.set_title('CatBoost Poverty Classification\\n(Predicted)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Longitude')\n",
    "    ax3.set_ylabel('Latitude')\n",
    "    ax3.grid(True, alpha=0.2)\n",
    "    \n",
    "    # Count cells in each class\n",
    "    print(\"\\nCatBoost Poverty Classification:\")\n",
    "    for class_name in ['Low (<30%)', 'Medium (30-50%)', 'High (50-70%)', 'Very High (>70%)']:\n",
    "        count = (grid_gdf['poverty_class'] == class_name).sum()\n",
    "        pct = count / len(grid_gdf) * 100\n",
    "        print(f\"  {class_name}: {count} cells ({pct:.1f}%)\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # MAP 4: Comparison - Actual vs Predicted (side by side if available)\n",
    "    # ============================================================================\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    if 'poverty_rate' in grid_gdf.columns:\n",
    "        # Show actual poverty rate for training cells\n",
    "        training_cells = grid_gdf[grid_gdf['poverty_rate'].notna()].copy()\n",
    "        \n",
    "        training_cells.plot(column='poverty_rate', \n",
    "                          ax=ax4, \n",
    "                          cmap='RdYlGn_r', \n",
    "                          legend=True,\n",
    "                          vmin=0, vmax=1,\n",
    "                          edgecolor='gray',\n",
    "                          linewidth=0.1,\n",
    "                          legend_kwds={'label': 'Actual Poverty Rate', 'shrink': 0.8})\n",
    "        \n",
    "        ax4.set_title(f'Actual Poverty Rate\\n(Training Cells: {len(training_cells)})', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    else:\n",
    "        # Show statistics instead\n",
    "        ax4.text(0.5, 0.5, 'No actual data available', \n",
    "                ha='center', va='center', transform=ax4.transAxes, fontsize=12)\n",
    "        ax4.set_title('Actual Poverty Rate', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax4.set_xlabel('Longitude')\n",
    "    ax4.set_ylabel('Latitude')\n",
    "    ax4.grid(True, alpha=0.2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(VIS_OUT / 'catboost_poverty_maps.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Saved {VIS_OUT / 'catboost_poverty_maps.png'}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # SUMMARY STATISTICS\n",
    "    # ============================================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CATBOOST SUMMARY STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nGrid-Level Statistics:\")\n",
    "    print(f\"  Total cells: {len(grid_gdf)}\")\n",
    "    if 'poverty_rate' in grid_gdf.columns:\n",
    "        training_cells = grid_gdf[grid_gdf['poverty_rate'].notna()]\n",
    "        print(f\"  Training cells: {len(training_cells)}\")\n",
    "        print(f\"  Mean poverty rate (actual): {training_cells['poverty_rate'].mean():.3f}\")\n",
    "        print(f\"  Mean poverty rate (predicted): {training_cells['poverty_rate_predicted'].mean():.3f}\")\n",
    "        print(f\"  Std dev (actual): {training_cells['poverty_rate'].std():.3f}\")\n",
    "        print(f\"  Std dev (predicted): {training_cells['poverty_rate_predicted'].std():.3f}\")\n",
    "        if 'error' in training_cells.columns:\n",
    "            print(f\"  Mean absolute error: {training_cells['error'].mean():.3f}\")\n",
    "            print(f\"  Max error: {training_cells['error'].max():.3f}\")\n",
    "    else:\n",
    "        print(f\"  Mean poverty rate (predicted): {grid_gdf['poverty_rate_predicted'].mean():.3f}\")\n",
    "        print(f\"  Std dev (predicted): {grid_gdf['poverty_rate_predicted'].std():.3f}\")\n",
    "    \n",
    "    print(f\"\\nPoverty Distribution:\")\n",
    "    print(f\"  Min predicted: {grid_gdf['poverty_rate_predicted'].min():.3f}\")\n",
    "    print(f\"  Max predicted: {grid_gdf['poverty_rate_predicted'].max():.3f}\")\n",
    "    print(f\"  Median predicted: {grid_gdf['poverty_rate_predicted'].median():.3f}\")\n",
    "    \n",
    "    print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
